{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to python script, remember to delete/comment the next line in the actual file\n",
    "# ! jupyter nbconvert --to python twoClassClassification.ipynb --output test14-8.py\n",
    "\n",
    "# # Run the notebook in Simpson GPU server\n",
    "# CUDA_VISIBLE_DEVICES=0 python testSamples2-8.py -batchSize=16 -epochs=100 -lr=0.001 -evalDetailLine=\"majourity voting on smote with 2 clases\" -hasBackground=f -usesLargestBox=f -segmentsMultiple=12 -dropoutRate=0.2 -grouped2D=t -modelChosen='Small2D' -votingSystem='majority'\n",
    "# CUDA_VISIBLE_DEVICES=1 python test14-8.py && CUDA_VISIBLE_DEVICES=1 python test14-8.py\n",
    "\n",
    "## Instantiate the values of the model\n",
    "# python testSamples2-8.py -batchSize=8 -epochs=100 -lr=0.001 -evalDetailLine=\"majourity voting on new data\" -hasBackground=f -usesLargestBox=f -segmentsMultiple=12 -dropoutRate=0.2 -grouped2D=t -modelChosen='Small2D' -votingSystem='majority'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image reading and file handling \n",
    "import pandas as pd\n",
    "import SimpleITK as sitk \n",
    "import os \n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Image agumentaitons \n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Saving History\n",
    "import pickle as pkl\n",
    "\n",
    "# Train test set spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# Dataset building\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Model building\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import timm # For Xception model\n",
    "\n",
    "# Evaluation metrics and Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Import the methods from twoClassClassificationMethods\n",
    "# import sys, importlib\n",
    "# importlib.reload(sys.modules['ipynb.fs.full.twoClassClassificaitonMethods'])\n",
    "# from ipynb.fs.full.twoClassClassificaitonMethods import *\n",
    "# importlib.reload(sys.modules['twoClassClassificaitonMethods'])\n",
    "from twoClassClassificationMethods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip freeze > requirements.txt\n",
    "# ! pip uninstall -y -r requirements.txt\n",
    "\n",
    "## Make a python environment\n",
    "# ! python3.8 -m venv threeDresearchPip\n",
    "\n",
    "## Download necessary packages \n",
    "# ! pip install matplotlib opencv-python scipy simpleitk pandas openpyxl scikit-learn nbconvert imblearn\n",
    "# ! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 \n",
    "\n",
    "## May need to download networkx 3.1 because of older python version of torch\n",
    "# ! pip install networkx==3.1\n",
    "\n",
    "## For 3D image classification\n",
    "# ! pip install foundation-cancer-image-biomarker -qq\n",
    "# ! pip install foundation-cancer-image-biomarker\n",
    "# ! pip3 install torchio\n",
    "\n",
    "## In case pip breaks \n",
    "# ! python -m ensurepip --upgrade\n",
    "\n",
    "## Check python version and packages\n",
    "# ! python --version\n",
    "# ! pip3 freeze > research3D.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def generateKFoldsValidation(testInformation, dataset, dataframe, k=2, trainingTransform=None):\n",
    "    \n",
    "#     testInformation = {\n",
    "#     'testName' : testName,\n",
    "#     'batchSize': batchSize,\n",
    "#     'numOfEpochs': numOfEpochs,\n",
    "#     'evalDetailLine': evalDetailLine,\n",
    "#     'learningRate': learningRate,\n",
    "#     'hasBackground': hasBackground,\n",
    "#     'usesLargestBox': usesLargestBox,\n",
    "#     'segmentsMultiple': segmentsMultiple,\n",
    "#     'grouped2D': grouped2D,\n",
    "#     'weight_decay': weight_decay,\n",
    "#     'modelChosen': modelChosen,\n",
    "#     'votingSystem': votingSystem,\n",
    "#     'patience': patience,\n",
    "#     'sampleStrategy': sampleStrategy\n",
    "# }\n",
    "    randomSeed = 42\n",
    "    seed_everything(randomSeed)\n",
    "\n",
    "    patients = list(dataset.keys())\n",
    "    fakeData = [-1] * len(patients)\n",
    "    stratifiedFolds = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    stratifiedFolds.get_n_splits(patients, fakeData)\n",
    "    splits = enumerate(stratifiedFolds.split(patients,fakeData))\n",
    "\n",
    "\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    recalls = []\n",
    "    predictionSplits = []\n",
    "    precisions = []\n",
    "    rocAucs = []\n",
    "    endingEpochs = []\n",
    "\n",
    "    histories = []\n",
    "    confusion_matricies = []\n",
    "    rocCurves = []\n",
    "\n",
    "    print(f\"\\n\\n====================Begin testing for {testInformation['evalDetailLine']}====================\")\n",
    "\n",
    "    for i, (trainIndicies, testIndicies) in splits:\n",
    "        patients = list(dataset.keys())\n",
    "        trainFolders = [patients[i] for i in trainIndicies]\n",
    "        testFolders = [patients[i] for i in testIndicies]\n",
    "        valFolders = testFolders\n",
    "\n",
    "        trainData, valData, testData, training_data_transforms = convertDataToLoaders(trainFolders, valFolders, testFolders, dataset, \n",
    "                                                                                      testInformation['modelChosen'], testInformation['grouped2D'], \n",
    "                                                                                      testInformation['segmentsMultiple'], training_data_transforms = None, \n",
    "                                                                                      batchSize=testInformation['batchSize'])\n",
    "        \n",
    "\n",
    "        print(f\"\\n--------------------------------{testInformation['evalDetailLine']} -- Fold #{i+1}--------------------------------\")\n",
    "        print('Train Data:', len(trainData))\n",
    "        print('Validation Data:', len(valData))\n",
    "        print('Test Data:', len(testData))\n",
    "\n",
    "\n",
    "        resultName = 'Tests/'+testInformation['testName']+'/'+testInformation['evalDetailLine']\n",
    "        resultNameWithFold = resultName+f'/fold-{i+1}/'\n",
    "\n",
    "        ## Select and Train Model\n",
    "        model, criterion, scheduler, optimizer = defineModel(learningRate=testInformation['learningRate'], weight_decay=testInformation['weight_decay'], \n",
    "                                                             model = testInformation['modelChosen'])\n",
    "        model, criterion, device, history, endingEpoch = trainModel(model, criterion, scheduler, optimizer, trainData, valData, \n",
    "                                                                    patience=testInformation['patience'],numOfEpochs=testInformation['numOfEpochs'])\n",
    "\n",
    "        saveResults(resultNameWithFold, model, history, training_data_transforms, saveModel=False)\n",
    "\n",
    "        #Evaluate perforamnce on test set\n",
    "        confusionMatrixDisp, rocCurveDisplay, testingMetrics = evaluateModelOnTestSet(resultNameWithFold, model, testData, criterion, device, \n",
    "                                                                                      testInformation['votingSystem'], testInformation['segmentsMultiple'], \n",
    "                                                                                      saveConfusionMatrix = False, showConfusionMatrix=False,\n",
    "                                                                                      showROCCurve=False, saveROCCurve=False)\n",
    "        \n",
    "        plotTraining(resultNameWithFold, '-', history, saveFigure=False, showResult=False)\n",
    "\n",
    "        # Collect metrics\n",
    "        accuracies.append(testingMetrics['Accuracy'])\n",
    "        f1s.append(testingMetrics['F1'])\n",
    "        recalls.append(testingMetrics['Recall'])\n",
    "        predictionSplits.append(testingMetrics['PredictionSplits'])\n",
    "        precisions.append(testingMetrics['Precision'])\n",
    "        rocAucs.append(testingMetrics['ROC-AUC'])\n",
    "        endingEpochs.append(endingEpoch)\n",
    "        \n",
    "        histories.append(history)\n",
    "        confusion_matricies.append(confusionMatrixDisp)\n",
    "        rocCurves.append(rocCurveDisplay)\n",
    "\n",
    "    kFoldsTestMetrics = {'Accuracy':meanConfidenceInterval(accuracies), 'F1':averageMultilabelMetricScores(f1s), 'Recall':averageMultilabelMetricScores(recalls), \n",
    "                    'PredictionSplits':averagePredictionTotals(predictionSplits), 'Precision':averageMultilabelMetricScores(precisions), \n",
    "                    'ROC-AUC':meanConfidenceInterval(rocAucs), 'endingEpochs':endingEpochs}\n",
    "    \n",
    "    # Write the test information and testvalues to files\n",
    "    print(f\"\\n--------------------------------{testInformation['evalDetailLine']} -- AVERAGES --------------------------------\")\n",
    "    writeDictionaryToTxtFile(resultName+'/kFoldsTestMetrics.txt',kFoldsTestMetrics, printLine=True)\n",
    "    writeDictionaryToTxtFile(resultName+'/testInformation.txt',testInformation, printLine=False)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    # Plot training, confusion matrix, and roc curves for each fold as a single .png\n",
    "    plotConfusionMatricies(resultName, f\"{testInformation['evalDetailLine']}\", confusion_matricies)\n",
    "    plotROCCurves(resultName, f\"{testInformation['evalDetailLine']}\", rocCurves)\n",
    "    plotTrainingPerformances(resultName, f\"{testInformation['evalDetailLine']}\", histories, saveFigure=True, showResult=True)\n",
    "\n",
    "    appendMetricsToXLSX(testInformation['evalDetailLine'], testInformation['testName'], kFoldsTestMetrics, dataframe)\n",
    "\n",
    "    #Make copies of the two scripts\n",
    "    for filename in os.listdir():\n",
    "        # Check if the file ends with .py\n",
    "        if filename.endswith('.py'):\n",
    "            # Copy the .py file\n",
    "            shutil.copy(filename, resultName+'/'+filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFromPickle(name):\n",
    "    with open(f'{name}.pkl', 'rb') as fp:\n",
    "        data = pkl.load(fp)\n",
    "    return data  \n",
    "\n",
    "def getDatasetShape(data):\n",
    "    imageSize = data[list(data.keys())[0]]['images'].shape\n",
    "    return [len(data), imageSize[0],imageSize[1],imageSize[2]]\n",
    "\n",
    "def checkShapesConsistent(data):\n",
    "    keys = list(data.keys())\n",
    "    size = data[keys[0]]['images'].shape\n",
    "    for i in range(len(data)):    \n",
    "        if size != data[keys[i]]['images'].shape:\n",
    "            print(f\"Error in shape at index {i} with shape {data[keys[i]]['images'].shape}\")\n",
    "            return False , size\n",
    "    return True , size\n",
    "    \n",
    "def getDataset(testInformation):\n",
    "    # Set random seeds\n",
    "    randomSeed = 42\n",
    "    seed_everything(randomSeed)\n",
    "\n",
    "    ## LOAD THE DATA\n",
    "    ## ==============================================================================================================\n",
    "    name = f\"preprocessCombinations/hasBackground={testInformation['hasBackground']}-usesLargestBox={testInformation['usesLargestBox']}-segmentsMultiple={testInformation['segmentsMultiple']}-size=(119,119)\"\n",
    "\n",
    "    dataset = loadFromPickle(name)\n",
    "    consitencyCheck, instanceSize = checkShapesConsistent(dataset)\n",
    "    print('Sizes are all the same? ', consitencyCheck)\n",
    "    assert consitencyCheck\n",
    "    print(f'dataset shape:')\n",
    "    print(len(dataset), instanceSize)\n",
    "\n",
    "\n",
    "    ## SPLIT THE DATA\n",
    "    if testInformation['sampleStrategy'] == 'underSampling':\n",
    "        dataset = underSampleData(dataset)\n",
    "        \n",
    "    # if sampleStrategy == 'overSampling':\n",
    "    #     trainData = overSampleData(trainFolders)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testName: testSamples14-8/gridSearchResNet50Small2D-segmentsMultiple=12\n",
      "evalDetailLine: -modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=16-patience=5\n",
      "batchSize: 16\n",
      "numOfEpochs: 50\n",
      "learningRate: 0.001\n",
      "hasBackground: True\n",
      "usesLargestBox: True\n",
      "segmentsMultiple: 12\n",
      "grouped2D: True\n",
      "weight_decay: 0.01\n",
      "modelChosen: ResNet50Small2D\n",
      "votingSystem: average\n",
      "patience: 5\n",
      "sampleStrategy: underSampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SimpsonLab\\threeDresearchPip\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes are all the same?  True\n",
      "dataset shape:\n",
      "89 (12, 118, 118)\n",
      "previous difference 33\n",
      "[61, 12, 2, 69, 28, 26, 22, 13, 84, 11, 64, 75, 53, 10, 57, 43, 4, 86, 71, 21, 77, 51, 58, 72, 54, 19, 70, 42, 88, 44, 29, 76, 40]\n",
      "33\n",
      "New difference after undersampling 0\n",
      "56\n",
      "\n",
      "\n",
      "====================Begin testing for -modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=16-patience=5====================\n",
      "44 12 12\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 95\u001b[0m\n\u001b[0;32m     57\u001b[0m                         gridSearch(testInformation)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m## Reproduce the best model  \u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m##-modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=32-patience=5\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# testName = 'testSamples14-8/gridSearchResnet'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# gridSearch(testInformation)\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43msetGridSearchParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 57\u001b[0m, in \u001b[0;36msetGridSearchParams\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m evalDetailLine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-modelChosen=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelChosen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearningRate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-weight_decay=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-batchSize=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatchSize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-patience=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatience\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m testInformation \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestName\u001b[39m\u001b[38;5;124m'\u001b[39m : testName,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalDetailLine\u001b[39m\u001b[38;5;124m'\u001b[39m : evalDetailLine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampleStrategy\u001b[39m\u001b[38;5;124m'\u001b[39m: sampleStrategy\n\u001b[0;32m     56\u001b[0m }\n\u001b[1;32m---> 57\u001b[0m \u001b[43mgridSearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestInformation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mgridSearch\u001b[1;34m(testInformation)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#addEvalDetailToModel(testInformation['evalDetailLine'],dataframe)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m getDataset(testInformation)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mgenerateKFoldsValidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestInformation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainingTransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[0;32m     14\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mto_excel(dataframePath, sheetName, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m, in \u001b[0;36mgenerateKFoldsValidation\u001b[1;34m(testInformation, dataset, dataframe, k, trainingTransform)\u001b[0m\n\u001b[0;32m     48\u001b[0m valFolders \u001b[38;5;241m=\u001b[39m testFolders\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trainFolders), \u001b[38;5;28mlen\u001b[39m(valFolders), \u001b[38;5;28mlen\u001b[39m(testFolders)) \n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     52\u001b[0m trainData, valData, testData, training_data_transforms \u001b[38;5;241m=\u001b[39m convertDataToLoaders(trainFolders, valFolders, testFolders, dataset, \n\u001b[0;32m     53\u001b[0m                                                                               testInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelChosen\u001b[39m\u001b[38;5;124m'\u001b[39m], testInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrouped2D\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     54\u001b[0m                                                                               testInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentsMultiple\u001b[39m\u001b[38;5;124m'\u001b[39m], training_data_transforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m     55\u001b[0m                                                                               batchSize\u001b[38;5;241m=\u001b[39mtestInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatchSize\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------------------\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalDetailLine\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -- Fold #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = ['TestName','RunData','PredictionSplits','Accuracy','F1Average','RecallAverage','PrecisionAverage','ROC-AUC','EndingEpoch','AccuracyData','F1Data','RecallData','PrecisionData','ROC-AUCData']\n",
    "dataframePath='testResultsNew.xlsx'\n",
    "sheetName = 'KFolds'\n",
    "\n",
    "def gridSearch(testInformation):\n",
    "    for key, value in testInformation.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "    dataframe = pd.read_excel(dataframePath, sheetName,header=None, names=columns)\n",
    "    #addEvalDetailToModel(testInformation['evalDetailLine'],dataframe)\n",
    "\n",
    "    dataset = getDataset(testInformation)\n",
    "    generateKFoldsValidation(testInformation, dataset, dataframe, k=5, trainingTransform=None) \n",
    "    dataframe.to_excel(dataframePath, sheetName, index=False, header=False)\n",
    "\n",
    "def setGridSearchParams():\n",
    "\n",
    "    # Data Parameters\n",
    "    testName = 'testSamples14-8/gridSearchInception'\n",
    "    evalDetailLine = \"test if k folds works\"\n",
    "    # batchSize = 16\n",
    "    numOfEpochs = 50\n",
    "    # learningRate = 0.001\n",
    "    hasBackground = True\n",
    "    usesLargestBox = True\n",
    "    segmentsMultiple = 12\n",
    "    grouped2D = True\n",
    "    weight_decay = 0.01\n",
    "    modelChosen = 'InceptionV3Small2D' #'ResNet50Small2D', 'VGG16Small2D', 'InceptionV3Small2D'\n",
    "    votingSystem = 'average' #average, singleLargest\n",
    "    patience = 10\n",
    "    sampleStrategy = 'underSampling' # 'underSampling', 'overSampling', 'normal' \n",
    "\n",
    "    for modelChosen in ['ResNet50Small2D','InceptionV3Small2D','VGG16Small2D']: #, 'ResNet50Small2D','InceptionV3Small2D','VGG16Small2D', 'XceptionSmall2D']:\n",
    "        for learningRate in [0.001,0.0001]:\n",
    "            for weight_decay in [0.01,0.001]:\n",
    "                for batchSize in [16,32]:\n",
    "                    for patience in [5,10]:\n",
    "                        testName = f'testSamples14-8/gridSearch{modelChosen}-segmentsMultiple=12'\n",
    "                        evalDetailLine = f\"-modelChosen={modelChosen}-lr={learningRate}-weight_decay={weight_decay}-batchSize={batchSize}-patience={patience}\"\n",
    "                        testInformation = {\n",
    "                            'testName' : testName,\n",
    "                            'evalDetailLine' : evalDetailLine,\n",
    "                            'batchSize': batchSize,\n",
    "                            'numOfEpochs': numOfEpochs,\n",
    "                            'learningRate': learningRate,\n",
    "                            'hasBackground': hasBackground,\n",
    "                            'usesLargestBox': usesLargestBox,\n",
    "                            'segmentsMultiple': segmentsMultiple,\n",
    "                            'grouped2D': grouped2D,\n",
    "                            'weight_decay': weight_decay,\n",
    "                            'modelChosen': modelChosen,\n",
    "                            'votingSystem': votingSystem,\n",
    "                            'patience': patience,\n",
    "                            'sampleStrategy': sampleStrategy\n",
    "                        }\n",
    "                        gridSearch(testInformation)\n",
    "\n",
    "## Reproduce the best model  \n",
    "##-modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=32-patience=5\n",
    "# testName = 'testSamples14-8/gridSearchResnet'\n",
    "# evalDetailLine = \"see if segmentsMultiple=1 works with average\"\n",
    "# batchSize = 32\n",
    "# numOfEpochs = 50\n",
    "# learningRate = 0.001\n",
    "# hasBackground = True\n",
    "# usesLargestBox = True\n",
    "# segmentsMultiple = 6\n",
    "# grouped2D = True\n",
    "# weight_decay = 0.01\n",
    "# modelChosen = 'ResNet50Small2D' #'ResNet50Small2D', 'VGG16Small2D', 'InceptionV3Small2D'\n",
    "# votingSystem = 'average' #average, singleLargest\n",
    "# patience = 5\n",
    "# sampleStrategy = 'underSampling' # 'underSampling', 'overSampling', 'normal' \n",
    "\n",
    "# testInformation = {\n",
    "# 'testName' : testName,\n",
    "# 'evalDetailLine' : evalDetailLine,\n",
    "# 'batchSize': batchSize,\n",
    "# 'numOfEpochs': numOfEpochs,\n",
    "# 'learningRate': learningRate,\n",
    "# 'hasBackground': hasBackground,\n",
    "# 'usesLargestBox': usesLargestBox,\n",
    "# 'segmentsMultiple': segmentsMultiple,\n",
    "# 'grouped2D': grouped2D,\n",
    "# 'weight_decay': weight_decay,\n",
    "# 'modelChosen': modelChosen,\n",
    "# 'votingSystem': votingSystem,\n",
    "# 'patience': patience,\n",
    "# 'sampleStrategy': sampleStrategy\n",
    "# }\n",
    "# gridSearch(testInformation)\n",
    "\n",
    "\n",
    "setGridSearchParams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
