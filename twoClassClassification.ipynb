{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook twoClassClassification.ipynb to python\n",
      "[NbConvertApp] Writing 21278 bytes to testSamples21-11.py\n"
     ]
    }
   ],
   "source": [
    "# # Convert to python script, remember to delete/comment the next line in the actual file\n",
    "# ! jupyter nbconvert --to python twoClassClassification.ipynb --output testSamples21-11.py\n",
    "\n",
    "# # Run the notebook in Simpson GPU server\n",
    "# CUDA_VISIBLE_DEVICES=0 python testSamples2-8.py -batchSize=16 -epochs=100 -lr=0.001 -evalDetailLine=\"majourity voting on smote with 2 clases\" -hasBackground=f -usesLargestBox=f -segmentsMultiple=12 -dropoutRate=0.2 -grouped2D=t -modelChosen='Small2D' -votingSystem='majority'\n",
    "# CUDA_VISIBLE_DEVICES=1 python test14-8.py && CUDA_VISIBLE_DEVICES=1 python test14-8.py\n",
    "\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=2 python testSamples11-11.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image reading and file handling \n",
    "import pandas as pd\n",
    "import SimpleITK as sitk \n",
    "import os \n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Image agumentaitons \n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Saving History\n",
    "import pickle as pkl\n",
    "\n",
    "# Train test set spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# Dataset building\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Model building\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import timm # For Xception model\n",
    "\n",
    "# Evaluation metrics and Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Import the methods from twoClassClassificationMethods\n",
    "# import sys, importlib\n",
    "# importlib.reload(sys.modules['ipynb.fs.full.twoClassClassificaitonMethods'])\n",
    "# from ipynb.fs.full.twoClassClassificaitonMethods import *\n",
    "# importlib.reload(sys.modules['twoClassClassificaitonMethods'])\n",
    "from twoClassClassificationMethods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip freeze > requirements.txt\n",
    "# ! pip uninstall -y -r requirements.txt\n",
    "\n",
    "## Make a python environment\n",
    "# ! python3.8 -m venv threeDresearchPip\n",
    "\n",
    "## Download necessary packages \n",
    "# ! pip install matplotlib opencv-python scipy simpleitk pandas openpyxl scikit-learn nbconvert imblearn\n",
    "# ! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 \n",
    "\n",
    "## May need to download networkx 3.1 because of older python version of torch\n",
    "# ! pip install networkx==3.1\n",
    "\n",
    "## For 3D image classification\n",
    "# ! pip install foundation-cancer-image-biomarker -qq\n",
    "# ! pip install foundation-cancer-image-biomarker\n",
    "# ! pip3 install torchio\n",
    "\n",
    "## In case pip breaks \n",
    "# ! python -m ensurepip --upgrade\n",
    "\n",
    "## Check python version and packages\n",
    "# ! python --version\n",
    "# ! pip3 freeze > research3D.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendTestToDictionary(votingResults, testingMetrics,endingEpoch,history,confusionMatrixDisp,rocCurveDisplay, model):\n",
    "\n",
    "    votingResults[\"accuracies\"].append(testingMetrics['Accuracy'])\n",
    "    votingResults[\"f1s\"].append(testingMetrics['F1'])\n",
    "    votingResults[\"recalls\"].append(testingMetrics['Recall'])\n",
    "    votingResults[\"predictionSplits\"].append(testingMetrics['PredictionSplits'])\n",
    "    votingResults[\"precisions\"].append(testingMetrics['Precision'])\n",
    "    votingResults[\"rocAucs\"].append(testingMetrics['ROC-AUC'])\n",
    "    votingResults[\"endingEpochs\"].append(endingEpoch)\n",
    "    \n",
    "    votingResults[\"histories\"].append(history)\n",
    "    votingResults[\"confusion_matricies\"].append(confusionMatrixDisp)\n",
    "    votingResults[\"rocCurves\"].append(rocCurveDisplay)\n",
    "\n",
    "    votingResults[\"models\"].append(model)\n",
    "    return votingResults\n",
    "\n",
    "def saveTestResults(votingResults, resultName, testInformation, dataframe, saveMaxAUCModel=True):\n",
    "    kFoldsTestMetrics = {'Accuracy':meanConfidenceInterval(votingResults[\"accuracies\"]), \n",
    "                        'F1':averageMultilabelMetricScores(votingResults[\"f1s\"]), \n",
    "                        'Recall':averageMultilabelMetricScores(votingResults[\"recalls\"]), \n",
    "                'PredictionSplits':averagePredictionTotals(votingResults[\"predictionSplits\"]), \n",
    "                'Precision':averageMultilabelMetricScores(votingResults[\"precisions\"]), \n",
    "                'ROC-AUC':meanConfidenceInterval(votingResults[\"rocAucs\"]), \n",
    "                'endingEpochs':votingResults[\"endingEpochs\"]}\n",
    "    \n",
    "    os.makedirs(resultName)\n",
    "    # Write the test information and testvalues to files\n",
    "    print(f\"\\n--------------------------------{testInformation['evalDetailLine']} -- AVERAGES --------------------------------\")\n",
    "    writeDictionaryToTxtFile(resultName+'/kFoldsTestMetrics.txt',kFoldsTestMetrics, printLine=True)\n",
    "    writeDictionaryToTxtFile(resultName+'/testInformation.txt',testInformation, printLine=False)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    # Plot training, confusion matrix, and roc curves for each fold as a single .png\n",
    "    plotConfusionMatricies(resultName, f\"{testInformation['evalDetailLine']}\", votingResults[\"confusion_matricies\"])\n",
    "    plotROCCurves(resultName, f\"{testInformation['evalDetailLine']}\", votingResults[\"rocCurves\"])\n",
    "    plotTrainingPerformances(resultName, f\"{testInformation['evalDetailLine']}\", votingResults[\"histories\"], saveFigure=True, showResult=True)\n",
    "\n",
    "    # save the model\n",
    "    if saveMaxAUCModel:\n",
    "        torch.save(votingResults[\"models\"][np.argmax(votingResults['rocAucs'])].state_dict(), resultName+'/maxAUCModel.pt')\n",
    "\n",
    "    appendMetricsToXLSX(testInformation['evalDetailLine'], testInformation['testName'], kFoldsTestMetrics, dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generateKFoldsValidation(testInformation, dataset, dataframes, k=5):\n",
    "#     testInformation = {\n",
    "#     'testName' : testName,\n",
    "#     'batchSize': batchSize,\n",
    "#     'numOfEpochs': numOfEpochs,\n",
    "#     'evalDetailLine': evalDetailLine,\n",
    "#     'learningRate': learningRate,\n",
    "#     'hasBackground': hasBackground,\n",
    "#     'usesLargestBox': usesLargestBox,\n",
    "#     'segmentsMultiple': segmentsMultiple,\n",
    "#     'grouped2D': grouped2D,\n",
    "#     'weight_decay': weight_decay,\n",
    "#     'modelChosen': modelChosen,\n",
    "#     'votingSystem': votingSystem,\n",
    "#     'patience': patience,\n",
    "#     'sampleStrategy': sampleStrategy,\n",
    "#     'training_data_transforms': training_data_transforms\n",
    "# }\n",
    "    randomSeed = 42\n",
    "    seed_everything(randomSeed)\n",
    "\n",
    "\n",
    "    # Get the testing set\n",
    "    patients = list(dataset.keys())\n",
    "    labels = [dataset[patient]['label'] for patient in patients]\n",
    "    \n",
    "    # Split the dataset into k folds\n",
    "    stratifiedFolds = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    stratifiedFolds.get_n_splits(patients, len(labels))\n",
    "    splits = enumerate(stratifiedFolds.split(patients,labels))\n",
    "\n",
    "    singleLargestVoting = {\n",
    "        \"accuracies\": [],\n",
    "        \"f1s\": [],\n",
    "        \"recalls\": [],\n",
    "        \"predictionSplits\": [],\n",
    "        \"precisions\": [],\n",
    "        \"rocAucs\": [],\n",
    "        \"endingEpochs\": [],\n",
    "        \"histories\": [],\n",
    "        \"confusion_matricies\": [],\n",
    "        \"rocCurves\": [],\n",
    "        \"models\": []\n",
    "    }\n",
    "    \n",
    "    averageVoting = {\n",
    "        \"accuracies\": [],\n",
    "        \"f1s\": [],\n",
    "        \"recalls\": [],\n",
    "        \"predictionSplits\": [],\n",
    "        \"precisions\": [],\n",
    "        \"rocAucs\": [],\n",
    "        \"endingEpochs\": [],\n",
    "        \"histories\": [],\n",
    "        \"confusion_matricies\": [],\n",
    "        \"rocCurves\": [],\n",
    "        \"models\": []\n",
    "    }\n",
    "    majorityVoting = {\n",
    "        \"accuracies\": [],\n",
    "        \"f1s\": [],\n",
    "        \"recalls\": [],\n",
    "        \"predictionSplits\": [],\n",
    "        \"precisions\": [],\n",
    "        \"rocAucs\": [],\n",
    "        \"endingEpochs\": [],\n",
    "        \"histories\": [],\n",
    "        \"confusion_matricies\": [],\n",
    "        \"rocCurves\": [],\n",
    "        \"models\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n\\n====================Begin testing for {testInformation['evalDetailLine']}====================\")\n",
    "\n",
    "    originalDataset = copy.deepcopy(dataset)\n",
    "\n",
    "    for i, (trainIndicies, valIndicies) in splits:\n",
    "        seed_everything(randomSeed)\n",
    "        dataset = copy.deepcopy(originalDataset)\n",
    "\n",
    "        patients = list(dataset.keys())\n",
    "        trainFolders = [patients[i] for i in trainIndicies]\n",
    "        valFolders = [patients[i] for i in valIndicies]\n",
    "        testFolders = [patients[i] for i in valIndicies]\n",
    "\n",
    "        if testInformation['sampleStrategy'] == 'overSampling':\n",
    "            dataset, trainFolders = oversampleData(dataset, trainFolders)\n",
    "        elif testInformation['sampleStrategy'] == 'underSampling':\n",
    "            dataset, trainFolders = underSampleData(dataset, trainFolders)\n",
    "                \n",
    "        trainData, valData, testData, training_data_transforms = convertDataToLoaders(trainFolders, valFolders, testFolders, dataset, \n",
    "                                                                                      testInformation['modelChosen'], testInformation['grouped2D'], \n",
    "                                                                                      testInformation['segmentsMultiple'], \n",
    "                                                                                      training_data_transforms = testInformation['training_data_transforms'], \n",
    "                                                                                      batchSize=testInformation['batchSize'])\n",
    "        \n",
    "\n",
    "        print(f\"\\n--------------------------------{testInformation['evalDetailLine']} -- Fold #{i+1}--------------------------------\")\n",
    "\n",
    "        print(f\"Train patients ({len(trainFolders)}):\", trainFolders)\n",
    "        print(f\"validation patients ({len(testFolders)}):\", valFolders)\n",
    "        print(f\"test patients ({len(testFolders)}):\", \"same as valFolders\" if testFolders==valFolders else testFolders)\n",
    "\n",
    "        trainFolderSplits = {0:0,1:0}\n",
    "        for patient in trainFolders:\n",
    "          if dataset[patient]['label']==torch.tensor(1, dtype=torch.float32):\n",
    "            trainFolderSplits[1] +=1\n",
    "          if dataset[patient]['label']==torch.tensor(0, dtype=torch.float32):\n",
    "            trainFolderSplits[0] +=1\n",
    "        \n",
    "        print(\"trainFolderSplits\",trainFolderSplits)\n",
    "        \n",
    "        valFolderSplits = {0:0,1:0}\n",
    "        for patient in valFolders:\n",
    "          if dataset[patient]['label']==torch.tensor(1, dtype=torch.float32):\n",
    "            valFolderSplits[1] +=1\n",
    "          if dataset[patient]['label']==torch.tensor(0, dtype=torch.float32):\n",
    "            valFolderSplits[0] +=1\n",
    "\n",
    "        print(\"valFolderSplits\",valFolderSplits)\n",
    "        \n",
    "        resultName = 'Tests/'+testInformation['testName']+'/'+testInformation['evalDetailLine']\n",
    "        resultNameWithFold = resultName+f'/fold-{i+1}/'\n",
    "\n",
    "        ## Select and Train Model\n",
    "        model, criterion, scheduler, optimizer = defineModel(learningRate=testInformation['learningRate'], weight_decay=testInformation['weight_decay'], \n",
    "                                                             model = testInformation['modelChosen'])\n",
    "        model, criterion, device, history, endingEpoch = trainModel(model, criterion, scheduler, optimizer, trainData, valData, \n",
    "                                                                    patience=testInformation['patience'],numOfEpochs=testInformation['numOfEpochs'])\n",
    "\n",
    "        saveResults(resultNameWithFold, model, history, training_data_transforms, saveTrainTransforms=False, saveModel=False)\n",
    "\n",
    "        ##Evaluate perforamnce on test set\n",
    "        # =============================================================================\n",
    "\n",
    "        if testInformation['votingSystem']=='singleLargest':\n",
    "            confusionMatrixDisp, rocCurveDisplay, testingMetrics = evaluateModelOnTestSet(resultNameWithFold, model, testData, criterion, device, \n",
    "                                                                                'singleLargest', 1, \n",
    "                                                                                saveConfusionMatrix = False, showConfusionMatrix=False,\n",
    "                                                                                showROCCurve=False, saveROCCurve=False)\n",
    "\n",
    "            plotTraining(resultNameWithFold, '-', history, saveFigure=False, showResult=False)\n",
    "            singleLargestVoting = appendTestToDictionary(singleLargestVoting, testingMetrics, endingEpoch,history,confusionMatrixDisp,rocCurveDisplay, model)\n",
    "\n",
    "        else:\n",
    "            confusionMatrixDisp, rocCurveDisplay, testingMetrics = evaluateModelOnTestSet(resultNameWithFold, model, testData, criterion, device, \n",
    "                                                                                        'average', testInformation['segmentsMultiple'], \n",
    "                                                                                        saveConfusionMatrix = False, showConfusionMatrix=False,\n",
    "                                                                                        showROCCurve=False, saveROCCurve=False)\n",
    "            \n",
    "            plotTraining(resultNameWithFold, '-', history, saveFigure=False, showResult=False)\n",
    "            averageVoting = appendTestToDictionary(averageVoting, testingMetrics, endingEpoch,history,confusionMatrixDisp,rocCurveDisplay, model)\n",
    "\n",
    "\n",
    "            confusionMatrixDisp, rocCurveDisplay, testingMetrics = evaluateModelOnTestSet(resultNameWithFold, model, testData, criterion, device, \n",
    "                                                                                        'majority', testInformation['segmentsMultiple'], \n",
    "                                                                                        saveConfusionMatrix = False, showConfusionMatrix=False,\n",
    "                                                                                        showROCCurve=False, saveROCCurve=False)\n",
    "            plotTraining(resultNameWithFold, '-', history, saveFigure=False, showResult=False)\n",
    "            majorityVoting = appendTestToDictionary(majorityVoting, testingMetrics, endingEpoch,history,confusionMatrixDisp,rocCurveDisplay, model)\n",
    "\n",
    "\n",
    "    if testInformation['votingSystem']== 'singleLargest':\n",
    "        saveTestResults(singleLargestVoting, resultName+'/singleLargestVoting', testInformation, dataframes['singleLargest.xlsx'])\n",
    "    else:\n",
    "        saveTestResults(averageVoting, resultName+'/averageVoting', testInformation, dataframes['average.xlsx'])\n",
    "        saveTestResults(majorityVoting, resultName+'/majorityVoting', testInformation, dataframes['majority.xlsx'])\n",
    "\n",
    "    #Make copies of the two scripts\n",
    "    for filename in os.listdir():\n",
    "        # Check if the file ends with .py\n",
    "        if filename.endswith('.py'):\n",
    "            # Copy the .py file\n",
    "            shutil.copy(filename, resultName+'/'+filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFromPickle(name):\n",
    "    with open(f'{name}.pkl', 'rb') as fp:\n",
    "        data = pkl.load(fp)\n",
    "    return data  \n",
    "\n",
    "def getDatasetShape(data):\n",
    "    imageSize = data[list(data.keys())[0]]['images'].shape\n",
    "    return [len(data), imageSize[0],imageSize[1],imageSize[2]]\n",
    "\n",
    "def checkShapesConsistent(data):\n",
    "    keys = list(data.keys())\n",
    "    size = data[keys[0]]['images'].shape\n",
    "    for i in range(len(data)):    \n",
    "        if size != data[keys[i]]['images'].shape:\n",
    "            print(f\"Error in shape at index {i} with shape {data[keys[i]]['images'].shape}\")\n",
    "            return False , size\n",
    "    return True , size\n",
    "    \n",
    "\n",
    "\n",
    "def getTestingSet(dataset):\n",
    "    \n",
    "    seed_everything(42)\n",
    "    # choose 14 samples of the 89 samples, for about 85% split between train and validation and 15% for test\n",
    "    # testSamples = random.sample(list(dataset.keys()), 14) \n",
    "    print('Testing set samples (key, classification):')\n",
    "    \n",
    "    # Have defined our test set from the above, hardcoding for validity\n",
    "    testSet = {\"CASE616\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE472\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE251\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE539\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE531\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE520\": torch.tensor(0, dtype=torch.float32),\n",
    "                \"CASE480\": torch.tensor(0, dtype=torch.float32),\n",
    "                \"CASE471\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE630\": torch.tensor(0, dtype=torch.float32),\n",
    "                \"CASE596\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE467\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE604\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE569\": torch.tensor(1, dtype=torch.float32),\n",
    "                \"CASE254\": torch.tensor(1, dtype=torch.float32)}\n",
    "    \n",
    "    for key in testSet:\n",
    "        print(key,dataset[key]['label'])\n",
    "    \n",
    "    return testSet\n",
    "\n",
    "def getDataset(testInformation):\n",
    "    # Set random seeds\n",
    "    randomSeed = 42\n",
    "    seed_everything(randomSeed)\n",
    "\n",
    "    ## LOAD THE DATA\n",
    "    ## ==============================================================================================================\n",
    "    name = f\"preprocessCombinations/hasBackground={testInformation['hasBackground']}-usesLargestBox={testInformation['usesLargestBox']}-segmentsMultiple={testInformation['segmentsMultiple']}-size=(119,119)\"\n",
    "    \n",
    "    dataset = loadFromPickle(name)\n",
    "    consitencyCheck, instanceSize = checkShapesConsistent(dataset)\n",
    "    print('Sizes are all the same? ', consitencyCheck)\n",
    "    assert consitencyCheck\n",
    "    print(f'dataset shape:')\n",
    "    print(len(dataset), instanceSize)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testName: testSamples14-8/gridSearchResNet50Small2D-segmentsMultiple=12\n",
      "evalDetailLine: -modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=16-patience=5\n",
      "batchSize: 16\n",
      "numOfEpochs: 50\n",
      "learningRate: 0.001\n",
      "hasBackground: True\n",
      "usesLargestBox: True\n",
      "segmentsMultiple: 12\n",
      "grouped2D: True\n",
      "weight_decay: 0.01\n",
      "modelChosen: ResNet50Small2D\n",
      "votingSystem: average\n",
      "patience: 5\n",
      "sampleStrategy: underSampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SimpsonLab\\threeDresearchPip\\lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes are all the same?  True\n",
      "dataset shape:\n",
      "89 (12, 118, 118)\n",
      "previous difference 33\n",
      "[61, 12, 2, 69, 28, 26, 22, 13, 84, 11, 64, 75, 53, 10, 57, 43, 4, 86, 71, 21, 77, 51, 58, 72, 54, 19, 70, 42, 88, 44, 29, 76, 40]\n",
      "33\n",
      "New difference after undersampling 0\n",
      "56\n",
      "\n",
      "\n",
      "====================Begin testing for -modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=16-patience=5====================\n",
      "44 12 12\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 95\u001b[0m\n\u001b[0;32m     57\u001b[0m                         gridSearch(testInformation)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m## Reproduce the best model  \u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m##-modelChosen=ResNet50Small2D-lr=0.001-weight_decay=0.01-batchSize=32-patience=5\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# testName = 'testSamples14-8/gridSearchResnet'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# gridSearch(testInformation)\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[43msetGridSearchParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 57\u001b[0m, in \u001b[0;36msetGridSearchParams\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m evalDetailLine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-modelChosen=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelChosen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearningRate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-weight_decay=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-batchSize=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatchSize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-patience=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatience\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m testInformation \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestName\u001b[39m\u001b[38;5;124m'\u001b[39m : testName,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalDetailLine\u001b[39m\u001b[38;5;124m'\u001b[39m : evalDetailLine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampleStrategy\u001b[39m\u001b[38;5;124m'\u001b[39m: sampleStrategy\n\u001b[0;32m     56\u001b[0m }\n\u001b[1;32m---> 57\u001b[0m \u001b[43mgridSearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestInformation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mgridSearch\u001b[1;34m(testInformation)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#addEvalDetailToModel(testInformation['evalDetailLine'],dataframe)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m getDataset(testInformation)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mgenerateKFoldsValidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestInformation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainingTransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[0;32m     14\u001b[0m dataframe\u001b[38;5;241m.\u001b[39mto_excel(dataframePath, sheetName, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 51\u001b[0m, in \u001b[0;36mgenerateKFoldsValidation\u001b[1;34m(testInformation, dataset, dataframe, k, trainingTransform)\u001b[0m\n\u001b[0;32m     48\u001b[0m valFolders \u001b[38;5;241m=\u001b[39m testFolders\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trainFolders), \u001b[38;5;28mlen\u001b[39m(valFolders), \u001b[38;5;28mlen\u001b[39m(testFolders)) \n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     52\u001b[0m trainData, valData, testData, training_data_transforms \u001b[38;5;241m=\u001b[39m convertDataToLoaders(trainFolders, valFolders, testFolders, dataset, \n\u001b[0;32m     53\u001b[0m                                                                               testInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelChosen\u001b[39m\u001b[38;5;124m'\u001b[39m], testInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrouped2D\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     54\u001b[0m                                                                               testInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentsMultiple\u001b[39m\u001b[38;5;124m'\u001b[39m], training_data_transforms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[0;32m     55\u001b[0m                                                                               batchSize\u001b[38;5;241m=\u001b[39mtestInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatchSize\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--------------------------------\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestInformation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalDetailLine\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -- Fold #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m--------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = ['TestName','RunData','PredictionSplits','Accuracy','F1','Recall','Precision','ROC-AUC','EndingEpoch','AccuracyData','F1Data','RecallData','PrecisionData','ROC-AUCData']\n",
    "#sheetName = 'KFolds'\n",
    "\n",
    "def getDataframes():\n",
    "    for sheetName in ['singleLargest.xlsx', 'average.xlsx', 'majority.xlsx']:\n",
    "        if not os.path.exists(sheetName): # Creates datasheet if it doesn't exist\n",
    "            dataframe = pd.DataFrame(columns=columns)\n",
    "            dataframe.to_excel(sheetName, index=False, engine='openpyxl')\n",
    "\n",
    "    dataframes = {\n",
    "        \"singleLargest.xlsx\": pd.read_excel('singleLargest.xlsx',header=None, names=columns, engine='openpyxl'),\n",
    "        \"average.xlsx\": pd.read_excel('average.xlsx',header=None, names=columns, engine='openpyxl'),\n",
    "        \"majority.xlsx\": pd.read_excel('majority.xlsx',header=None, names=columns, engine='openpyxl')\n",
    "    }\n",
    "    return dataframes \n",
    "\n",
    "\n",
    "def gridSearch(testInformation):\n",
    "    for key, value in testInformation.items():\n",
    "        print(f'{key}: {value}')\n",
    "\n",
    "    dataframes = getDataframes()\n",
    "    #addEvalDetailToModel(testInformation['evalDetailLine'],dataframe)\n",
    "\n",
    "    dataset = getDataset(testInformation)\n",
    "    generateKFoldsValidation(testInformation, dataset, dataframes, k=5) \n",
    "\n",
    "    for sheetName, dataframe in dataframes.items():\n",
    "        dataframe.to_excel(sheetName, index=False, header=False)\n",
    "\n",
    "def setGridSearchParams():\n",
    "    # Unchanging Data parameters\n",
    "    numOfEpochs = 50\n",
    "    hasBackground = True\n",
    "    usesLargestBox = True\n",
    "    # votingSystem = 'multiVoting' #average, singleLargest, majority, multiVoting\n",
    "    sampleStrategy = 'normal' # 'underSampling', 'overSampling', 'normal' \n",
    "\n",
    "    experimentName = f'testSamples21-11--normal'\n",
    "    training_data_transforms = None\n",
    "    # training_data_transforms = transforms.Compose([\n",
    "    #     transforms.RandomRotation(degrees=0.85),\n",
    "    #     transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #     transforms.RandomVerticalFlip(p=0.5)\n",
    "    # ]) \n",
    "\n",
    "    for segmentsMultiple in [3,6,9,12,1]:\n",
    "\n",
    "        if segmentsMultiple==1:\n",
    "            votingSystem = 'singleLargest'\n",
    "            grouped2D = False \n",
    "        else:\n",
    "            votingSystem = 'multiVoting'\n",
    "            grouped2D = True\n",
    "        for modelChosen in ['InceptionV3Small2D', 'ResNet50Small2D','VGG16Small2D','XceptionSmall2D']: #, 'ResNet50Small2D','InceptionV3Small2D','VGG16Small2D', 'XceptionSmall2D']:\n",
    "\n",
    "            ## Differentiate the start of the test with a line            \n",
    "            dataframes = getDataframes()\n",
    "            if votingSystem=='singleLargest':\n",
    "                addEvalDetailToModel(f\"{modelChosen}, segments={segmentsMultiple}, voting=singleLargest\", dataframes['singleLargest.xlsx'])\n",
    "            if votingSystem=='average' or votingSystem=='multiVoting':\n",
    "                addEvalDetailToModel(f\"{modelChosen}, segments={segmentsMultiple}, voting=average\", dataframes['average.xlsx'])\n",
    "            if votingSystem=='majority' or votingSystem=='multiVoting':\n",
    "                addEvalDetailToModel(f\"{modelChosen}, segments={segmentsMultiple}, voting=majority\", dataframes['majority.xlsx'])\n",
    "\n",
    "            for sheetName, dataframe in dataframes.items():\n",
    "                dataframe.to_excel(sheetName, index=False, header=False)\n",
    "            \n",
    "            # Beging hyperparemeterizing\n",
    "            for learningRate in [0.001,0.0001]:\n",
    "                for weight_decay in [0.01,0.001]:\n",
    "                    for batchSize in [8,16]:\n",
    "                        for patience in [5,10]:\n",
    "                            testName = f'{experimentName}/{modelChosen}-segmentsMultiple={segmentsMultiple}'\n",
    "                            evalDetailLine = f\"-modelChosen={modelChosen}-lr={learningRate}-weight_decay={weight_decay}-batchSize={batchSize}-patience={patience}\"\n",
    "                            testInformation = {\n",
    "                                'testName' : testName,\n",
    "                                'evalDetailLine' : evalDetailLine,\n",
    "                                'batchSize': batchSize,\n",
    "                                'numOfEpochs': numOfEpochs,\n",
    "                                'learningRate': learningRate,\n",
    "                                'hasBackground': hasBackground,\n",
    "                                'usesLargestBox': usesLargestBox,\n",
    "                                'segmentsMultiple': segmentsMultiple,\n",
    "                                'grouped2D': grouped2D,\n",
    "                                'weight_decay': weight_decay,\n",
    "                                'modelChosen': modelChosen,\n",
    "                                'votingSystem': votingSystem,\n",
    "                                'patience': patience,\n",
    "                                'sampleStrategy': sampleStrategy,\n",
    "                                'training_data_transforms': training_data_transforms\n",
    "                            }\n",
    "                            gridSearch(testInformation)\n",
    "\n",
    "setGridSearchParams()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "threeDresearchPip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
