{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nrrd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "import cv2\n",
    "import scipy\n",
    "\n",
    "import SimpleITK as sitk \n",
    "import os \n",
    "\n",
    "import ipynb \n",
    "import statistics\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data from the .xsxl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "columns = ['TAPS_CaseIDs_PreNAT','RECIST_PostNAT', 'Slice_Thickness']\n",
    "data = pd.read_excel('PDAC-Response_working.xlsx', header=None,names = columns)\n",
    "data.drop(0, inplace=True) # Remove the header row\n",
    "data=data.sort_values(by=['TAPS_CaseIDs_PreNAT'])\n",
    "\n",
    "# # Get the entire datasheet\n",
    "cases = list(data['TAPS_CaseIDs_PreNAT'])\n",
    "recistCriteria = list(data['RECIST_PostNAT'])\n",
    "print(len(recistCriteria))\n",
    "\n",
    "\n",
    "# # Remove all folders that have >13 slices in the datasheet\n",
    "# data.drop(data[data['Slice_Thickness'] <= 13].index, inplace = True)\n",
    "# print(list(data['Slice_Thickness']))\n",
    "# cases = list(data['TAPS_CaseIDs_PreNAT'])\n",
    "# recistCriteria = list(data['RECIST_PostNAT'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform preprocessing on multiple images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image_to_adbomen(image, window_center, window_width):\n",
    "    \n",
    "    img_max = window_center + int(window_width / 2)\n",
    "    img_min = window_center - int(window_width / 2)\n",
    "    return np.clip(image, img_min, img_max)\n",
    "\n",
    "def centerXYOfImage(overlay_mask, segment_mask, segmentedSlices, padding=25):\n",
    "    \"\"\" \n",
    "    Centers the X and Y of the image to crop the image. segmentedSlices is given as an array of z-value slices because the same approach to x_indicies and y_indicies does not work on overlay_segment (works for x and y though)\n",
    "    \"\"\"\n",
    "    x_indices, y_indices, _ = np.where(segment_mask == 1)\n",
    "    # Get the bounding box for x and y dimensions\n",
    "    min_x, max_x = x_indices.min(), x_indices.max()\n",
    "    min_y, max_y = y_indices.min(), y_indices.max()\n",
    "\n",
    "    center_x = (min_x + max_x) // 2\n",
    "    center_y = (min_y + max_y) // 2\n",
    "\n",
    "    width = abs(max_x - min_x) // 2\n",
    "    height = abs(max_y - min_y) // 2\n",
    "\n",
    "    \n",
    "    # Get the dimensions of the cropped image\n",
    "    start_x = max(0, center_x - width - padding)\n",
    "    end_x = min(segment_mask.shape[0], center_x + width + padding)\n",
    "    start_y = max(0, center_y - height - padding)\n",
    "    end_y = min(segment_mask.shape[1], center_y + height + padding)\n",
    "\n",
    "    # # Adjust the crop region if it's smaller than 100x100\n",
    "    # if end_x - start_x < 100:\n",
    "    #     if start_x == 0:\n",
    "    #         end_x = min(segment_mask.shape[0], 100)\n",
    "    #     elif end_x == segment_mask.shape[0]:\n",
    "    #         start_x = max(0, segment_mask.shape[0] - 100)\n",
    "    # if end_y - start_y < 100:\n",
    "    #     if start_y == 0:\n",
    "    #         end_y = min(segment_mask.shape[1], 100)\n",
    "    #     elif end_y == segment_mask.shape[1]:\n",
    "    #         start_y = max(0, segment_mask.shape[1] - 100)\n",
    "\n",
    "    segmentedSlices = np.sort(np.array(segmentedSlices))\n",
    "    return overlay_mask[start_x:end_x, start_y:end_y, np.array(segmentedSlices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertNdArrayToCV2Image(image, resolution = (64,64)):\n",
    "    \"\"\" Converts a numpy array to a cv2 image \"\"\"\n",
    "    image = np.array(image, dtype=np.uint8)\n",
    "    image = cv2.resize(image, resolution)\n",
    "    return image\n",
    "\n",
    "def makeAlign(image1,image2):\n",
    "    image1.SetDirection(image2.GetDirection())\n",
    "    image1.SetOrigin(image2.GetOrigin())\n",
    "    image1.SetSpacing(image2.GetSpacing())\n",
    "    return image1, image2\n",
    "\n",
    "def isAligned(image1, image2):\n",
    "    return image1.GetDirection() == image2.GetDirection() and image1.GetOrigin() == image2.GetOrigin() and image1.GetSpacing() == image2.GetSpacing()   \n",
    "\n",
    "def resampleSizes(wholeHeader, segmentHeader):\n",
    "    \"\"\" \n",
    "    Resamples the sitk image to have the same size based on the one with the largest size.\n",
    "    \"\"\"\n",
    "    if wholeHeader.GetSize()[-1] >= segmentHeader.GetSize()[-1]:\n",
    "        imageLarge = wholeHeader\n",
    "        imageSmall = segmentHeader\n",
    "        wholeThenSegmentOrder = True\n",
    "    else:\n",
    "        imageLarge = segmentHeader\n",
    "        imageSmall = wholeHeader \n",
    "        wholeThenSegmentOrder = False\n",
    "\n",
    "    resample = sitk.ResampleImageFilter()\n",
    "    resample.SetReferenceImage(imageLarge)  \n",
    "    resample.SetInterpolator(sitk.sitkLinear)  # Choose the interpolation method (sitkLinear, sitkNearestNeighbor, etc.)\n",
    "    resample.SetDefaultPixelValue(0)  # Set default pixel value for areas outside the original image\n",
    "\n",
    "    imageSmall = resample.Execute(imageSmall)\n",
    "\n",
    "    print(f'imageLarge: {imageLarge.GetSize()}')\n",
    "    print(f'imageSmall: {imageSmall.GetSize()}')\n",
    "    \n",
    "\n",
    "    if wholeThenSegmentOrder:\n",
    "        return imageLarge, imageSmall # whole, then segment\n",
    "    else:\n",
    "        return imageSmall, imageLarge # segment, then whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoImageAlignProceess(wholeHeader,segmentHeader,verbose):    \n",
    "\n",
    "    error = False\n",
    "    # Check if the images are aligned\n",
    "    wholeHeader, segmentHeader = makeAlign(wholeHeader, segmentHeader)\n",
    "    imagesAreAligned = isAligned(wholeHeader, segmentHeader)\n",
    "    print(f'Are the two images aligned now?: {imagesAreAligned}' if verbose==2 else '',end='')\n",
    "\n",
    "    if not imagesAreAligned:\n",
    "        error = True\n",
    "        return None, None, True\n",
    "    \n",
    "    # Set the spacing of the image to 1x1x1mm voxel spacing\n",
    "    wholeHeader.SetSpacing([1,1,1])\n",
    "    segmentHeader.SetSpacing([1,1,1])\n",
    "    imagesSpacingAligned = wholeHeader.GetSpacing() == segmentHeader.GetSpacing() \n",
    "    print(f'Are the two images aligned in terms of spacing?: {imagesSpacingAligned}' if verbose==2 else '',end='')\n",
    "\n",
    "    if not imagesSpacingAligned:\n",
    "        error = True\n",
    "        return None, None, True\n",
    "    \n",
    "\n",
    "    imagesSizeAligned = wholeHeader.GetSize() == segmentHeader.GetSize() \n",
    "    print(f'Are the two images aligned in terms of size?: {imagesSizeAligned}' if verbose==2 else '',end='')\n",
    "\n",
    "    if not imagesSizeAligned:\n",
    "        wholeHeader, segmentHeader = resampleSizes(wholeHeader, segmentHeader)\n",
    "        print(f'whole size: {wholeHeader.GetSize()}')\n",
    "        print(f'segment size: {segmentHeader.GetSize()}')\n",
    "        imagesSizeAligned = wholeHeader.GetSize() == segmentHeader.GetSize() \n",
    "        print(f'Are the two images aligned in terms of size now?: {imagesSizeAligned}' if verbose==2 else '',end='')\n",
    "        if not imagesSizeAligned:\n",
    "            error = True\n",
    "            return None, None, True\n",
    "\n",
    "    \n",
    "    return wholeHeader, segmentHeader, False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayCroppedSegmentations(croppedSegment):\n",
    "    print(f'CroppedSegment shape: {croppedSegment.shape}')\n",
    "    # Display the segmented image slices \n",
    "\n",
    "    columnLen = 10\n",
    "    rowLen = max(2,croppedSegment.shape[-1] // columnLen + 1) \n",
    "    figure,axis = plt.subplots( rowLen, columnLen, figsize=(10, 10))\n",
    "    \n",
    "    rowIdx = 0\n",
    "    for idx in range(croppedSegment.shape[-1]):        \n",
    "        if idx%columnLen == 0 and idx>0:\n",
    "            rowIdx += 1\n",
    "        axis[rowIdx][idx%columnLen].imshow(croppedSegment[:,:,idx], cmap=\"gray\")\n",
    "        axis[rowIdx][idx%columnLen].axis('off')\n",
    "\n",
    "    # Turn off the axis of the rest of the subplots\n",
    "    for i in range(idx+1, rowLen*columnLen):\n",
    "        if i%columnLen == 0:\n",
    "            rowIdx += 1\n",
    "        axis[rowIdx][i%columnLen].axis('off')\n",
    "    \n",
    "    # plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def displayOverlayedSegmentations(segmentedSlices, augmented_whole, augmented_segment):\n",
    "\n",
    "    maskedWhole = np.ma.masked_where(augmented_segment==1, augmented_whole)\n",
    "    # Display the segmented image slices \n",
    "\n",
    "    columnLen = 10\n",
    "    rowLen = max(2,len(segmentedSlices) // columnLen + 1) \n",
    "    figure,axis = plt.subplots( rowLen, columnLen, figsize=(6, 6))\n",
    "    rowIdx = 0\n",
    "    for idx in range(len(segmentedSlices)):        \n",
    "        if idx%columnLen == 0 and idx>0:\n",
    "            rowIdx += 1\n",
    "        axis[rowIdx][idx%columnLen].imshow(augmented_whole[:,:,segmentedSlices[idx]], cmap=\"gray\")\n",
    "        axis[rowIdx][idx%columnLen].imshow(augmented_segment[:,:,segmentedSlices[idx]], cmap=\"Blues\", alpha=0.75)\n",
    "        axis[rowIdx][idx%columnLen].axis('off')\n",
    "\n",
    "    # Turn off the axis of the rest of the subplots\n",
    "    for i in range(idx+1, rowLen*columnLen):\n",
    "        if i%columnLen == 0:\n",
    "            rowIdx += 1\n",
    "        axis[rowIdx][i%columnLen].axis('off')\n",
    "    \n",
    "    # plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(wholeHeader, segmentHeader, verbose=0):\n",
    "    \"\"\"\n",
    "    Preprocesses the wholeHeader and segmentHeader sitk images to be ready for augmentation \n",
    "    Verbose = 0: No output\n",
    "    Verbose = 1: Only the CT scans slices and the array of slices it uses\n",
    "    Verbose = 2: Everything\n",
    "    Verbose = 3: Show the segment mask on top of the whole CT scan\n",
    "\n",
    "    Returns: a np array windowed whole image, a np array cropped segment image to 64x64x[] resolution, and boolean error flag.\n",
    "    \"\"\"\n",
    "    error = False # Error flag to check if there was an error in the preprocessing\n",
    "\n",
    "    # Align the two images \n",
    "    wholeHeader, segmentHeader, error = twoImageAlignProceess(wholeHeader, segmentHeader, verbose) \n",
    "    if error:\n",
    "        return None, None, error\n",
    "    \n",
    "    # Convert the images into numpy arrays for further processing, take the transpose as the format is z,y,x\n",
    "    whole = sitk.GetArrayFromImage(wholeHeader).T\n",
    "    segment = sitk.GetArrayFromImage(segmentHeader).T\n",
    "\n",
    "    print(f'Spacing of whole:{whole.shape}' if verbose==2 else '',end='')\n",
    "    print(f'Spacing of segment:{segment.shape}' if verbose==2 else '',end='')\n",
    "    \n",
    "    # Windowing parameters for the abdomen\n",
    "    ABDOMEN_UPPER_BOUND = 215\n",
    "    ABDOMEN_LOWER_BOUND = -135\n",
    "    window_center = (ABDOMEN_UPPER_BOUND+ABDOMEN_LOWER_BOUND) / 2\n",
    "    window_width = (ABDOMEN_UPPER_BOUND-ABDOMEN_LOWER_BOUND) / 2\n",
    "\n",
    "    # Window and resample the whole image\n",
    "    augmented_whole = window_image_to_adbomen(whole, window_center, window_width)\n",
    "\n",
    "    # Get the slice indices where the segment is present in \n",
    "    augmented_segment = segment\n",
    "    segmentedSlices = [] \n",
    "    for index in range(augmented_segment.shape[-1]):\n",
    "        if len(np.unique(augmented_segment[:,:,index])) > 1:\n",
    "            segmentedSlices.append(index)\n",
    "\n",
    "    print(f'Segment slice indices:{segmentedSlices}' if verbose==2 else '',end='')\n",
    "\n",
    "\n",
    "    #Segment the whole image with the segment mask\n",
    "    overlay_segment = augmented_whole * augmented_segment    \n",
    "    croppedSegment = centerXYOfImage(overlay_segment,augmented_segment,segmentedSlices) # Crop the image to the center of the segmented region     \n",
    "\n",
    "    # croppedSegment[croppedSegment<0.0001]=0 # Window the image so that the background is completely black for all slices\n",
    "    croppedSegment = convertNdArrayToCV2Image(croppedSegment) # Convert the image to a cv2 image\n",
    "\n",
    "    #Display the results of preprocessing\n",
    "    if verbose==1 or verbose==2:\n",
    "        displayCroppedSegmentations(croppedSegment)\n",
    "    elif verbose==3:\n",
    "        displayOverlayedSegmentations(segmentedSlices, augmented_whole, augmented_segment)\n",
    "    \n",
    "    return whole, croppedSegment, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargestSlice(croppedSegment):\n",
    "    \"\"\"\n",
    "    Finds the index with the largest slice in the croppedSegment and returns the index as well as the sorted number of slices each index has\n",
    "    \"\"\"\n",
    "    max = 0\n",
    "    maxIndex = 0\n",
    "    \n",
    "    indices = []\n",
    "    sliceTotals = []\n",
    "    for idx in range(croppedSegment.shape[-1]):\n",
    "        unique, counts = np.unique(croppedSegment[:,:,idx], return_counts=True)\n",
    "        values = dict(zip(unique, counts))\n",
    "        sliceTotal = 0\n",
    "        for value,count in values.items():\n",
    "            sliceTotal += count if value > 0 else 0 \n",
    "        \n",
    "\n",
    "        indices.append(idx)\n",
    "        sliceTotals.append(sliceTotal)\n",
    "        \n",
    "        if sliceTotal > max: \n",
    "            max = sliceTotal\n",
    "            maxIndex = idx \n",
    "\n",
    "    values = dict(zip(sliceTotals,indices))\n",
    "    values = dict(sorted(values.items())) # Sort the values by number of slices\n",
    "\n",
    "    return maxIndex, values\n",
    "\n",
    "def updateSlices(croppedSegment, desiredNumberOfSlices=1):\n",
    "    \"\"\"\n",
    "    Updates the number of slices to the number of slices given. \n",
    "    If the numberOfSlices > the number of slices in the croppedSegment, it will duplicate the slices of the largest slices \n",
    "    If the numberOfSlices < the number of slices in the croppedSegment, it will remove the slices with the least amount of information \n",
    "    If the numberOfSlices == the number of slices in the croppedSegment, it will do nothing     \n",
    "    \"\"\"\n",
    "    if croppedSegment.shape[-1] == desiredNumberOfSlices:\n",
    "        return croppedSegment\n",
    "    elif croppedSegment.shape[-1] < desiredNumberOfSlices: # Duplicate slices from the largest slice\n",
    "\n",
    "        # Specifications of croppedSegment\n",
    "        original = np.copy(croppedSegment)\n",
    "        largestSliceIndex, _ = getLargestSlice(croppedSegment)\n",
    "        maxUpperBound = croppedSegment.shape[-1] -1\n",
    "        minLowerBound = 0\n",
    "        \n",
    "        # Specification of the values to duplicate\n",
    "        numToDuplication = desiredNumberOfSlices - croppedSegment.shape[-1] \n",
    "        ends = numToDuplication//2\n",
    "        lowerRemainder = abs(largestSliceIndex - ends) if (largestSliceIndex - ends) < minLowerBound else 0   \n",
    "        upperRemainder = abs(maxUpperBound - (largestSliceIndex + ends)) if largestSliceIndex + ends > maxUpperBound else 0 \n",
    "\n",
    "        #Printing of the of the specifications\n",
    "        # print(f'LargestSegmentIdx = {largestSliceIndex}\\nNumber of slices to duplicate: {numToDuplication}\\n Ends: {ends}, \\nlowerRemainder: {lowerRemainder},\\n upperRemainder: {upperRemainder}')\n",
    "        \n",
    "        #Making of the range to center the slices to duplicate\n",
    "        duplicationRange = list(range( largestSliceIndex - ends - upperRemainder + lowerRemainder , largestSliceIndex + ends + lowerRemainder - upperRemainder))\n",
    "\n",
    "        # print('preAdd',duplicationRange)\n",
    "        #Edge case where we only need 1 extra slice\n",
    "        if len(duplicationRange) == 0:\n",
    "            duplicationRange = [largestSliceIndex]\n",
    "\n",
    "        # Fixes the slices if we are off by 1\n",
    "        if len(duplicationRange)+croppedSegment.shape[-1] == desiredNumberOfSlices: \n",
    "            pass \n",
    "        else:\n",
    "            # Add to the right side if the left will be out of bounds\n",
    "            if duplicationRange[0] -1 < minLowerBound:\n",
    "                duplicationRange = duplicationRange + [duplicationRange[-1] + 1]\n",
    "            # Add to the left side if the right will be out of bounds\n",
    "            elif duplicationRange[-1] +1 > maxUpperBound:\n",
    "                duplicationRange = [duplicationRange[0] - 1] + duplicationRange\n",
    "            else: #Default, add to the right side\n",
    "                duplicationRange = duplicationRange + [duplicationRange[-1] + 1]\n",
    "                \n",
    "        # print(f'CroppedSlices={list(range(0,croppedSegment.shape[-1]))}\\nSlices: {duplicationRange}')\n",
    "        # print(len(duplicationRange)+croppedSegment.shape[-1])\n",
    "        assert(len(duplicationRange)+croppedSegment.shape[-1]== desiredNumberOfSlices) #Ensure that the desired number of slices is met\n",
    "\n",
    "        #Insert the values\n",
    "        croppedSegment = np.insert(croppedSegment, duplicationRange, original[:,:,duplicationRange], axis=-1)\n",
    "            \n",
    "        # print('greater than')\n",
    "        return croppedSegment\n",
    "    else:\n",
    "        # Specifications of croppedSegment\n",
    "        original = np.copy(croppedSegment)\n",
    "        _, sliceValues = getLargestSlice(croppedSegment)\n",
    "        numberOfSlicesToRemove =  croppedSegment.shape[-1] - desiredNumberOfSlices \n",
    "\n",
    "        # Remove the slices with the least amount of information\n",
    "        croppedSegment = np.delete(croppedSegment,list(sliceValues.values())[:numberOfSlicesToRemove], axis=-1)\n",
    "\n",
    "        # print('Less than')\n",
    "        return croppedSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "CASE244 All files read: True\n",
      "==============================================================\n",
      "CASE246 All files read: True\n",
      "==============================================================\n",
      "CASE247 All files read: True\n",
      "==============================================================\n",
      "CASE251 All files read: True\n",
      "==============================================================\n",
      "CASE254 All files read: True\n",
      "==============================================================\n",
      "CASE256 All files read: True\n",
      "==============================================================\n",
      "CASE263 All files read: True\n",
      "==============================================================\n",
      "CASE264 All files read: True\n",
      "==============================================================\n",
      "CASE265 All files read: True\n",
      "==============================================================\n",
      "CASE270 All files read: True\n",
      "==============================================================\n",
      "CASE274 All files read: True\n",
      "==============================================================\n",
      "CASE467 All files read: True\n",
      "==============================================================\n",
      "CASE468 All files read: True\n",
      "==============================================================\n",
      "CASE471 All files read: True\n",
      "==============================================================\n",
      "CASE472 All files read: True\n",
      "==============================================================\n",
      "CASE476 All files read: True\n",
      "==============================================================\n",
      "CASE479 All files read: True\n",
      "==============================================================\n",
      "CASE480 All files read: True\n",
      "==============================================================\n",
      "CASE482 All files read: True\n",
      "==============================================================\n",
      "CASE484 All files read: True\n",
      "==============================================================\n",
      "CASE485 All files read: True\n",
      "==============================================================\n",
      "CASE488 All files read: True\n",
      "==============================================================\n",
      "CASE494 All files read: True\n",
      "==============================================================\n",
      "CASE496 All files read: True\n",
      "==============================================================\n",
      "CASE499 All files read: True\n",
      "==============================================================\n",
      "CASE500 All files read: True\n",
      "==============================================================\n",
      "CASE505 All files read: True\n",
      "==============================================================\n",
      "CASE515 All files read: True\n",
      "==============================================================\n",
      "CASE523 All files read: True\n",
      "==============================================================\n",
      "CASE525 All files read: True\n",
      "==============================================================\n",
      "CASE531 All files read: True\n",
      "==============================================================\n",
      "CASE534 All files read: True\n",
      "==============================================================\n",
      "CASE535 All files read: True\n",
      "==============================================================\n",
      "CASE537 All files read: True\n",
      "==============================================================\n",
      "CASE539 All files read: True\n",
      "==============================================================\n",
      "CASE541 All files read: True\n",
      "==============================================================\n",
      "CASE543 All files read: True\n",
      "==============================================================\n",
      "CASE546 All files read: True\n",
      "==============================================================\n",
      "CASE547 All files read: True\n",
      "==============================================================\n",
      "CASE548 All files read: True\n",
      "==============================================================\n",
      "CASE549 All files read: True\n",
      "==============================================================\n",
      "CASE551 All files read: True\n",
      "==============================================================\n",
      "CASE554 All files read: True\n",
      "==============================================================\n",
      "CASE555 All files read: True\n",
      "==============================================================\n",
      "CASE557 All files read: True\n",
      "==============================================================\n",
      "CASE559 All files read: True\n",
      "==============================================================\n",
      "CASE560 All files read: True\n",
      "==============================================================\n",
      "CASE562 All files read: True\n",
      "==============================================================\n",
      "CASE563 All files read: True\n",
      "==============================================================\n",
      "CASE564 All files read: True\n",
      "==============================================================\n",
      "CASE565 All files read: True\n",
      "==============================================================\n",
      "CASE568 All files read: True\n",
      "==============================================================\n",
      "CASE569 All files read: True\n",
      "==============================================================\n",
      "CASE572 All files read: True\n",
      "==============================================================\n",
      "CASE574 All files read: True\n",
      "==============================================================\n",
      "CASE575 All files read: True\n",
      "==============================================================\n",
      "CASE577 All files read: True\n",
      "==============================================================\n",
      "CASE578 All files read: True\n",
      "==============================================================\n",
      "CASE580 All files read: True\n",
      "==============================================================\n",
      "CASE581 All files read: True\n",
      "==============================================================\n",
      "CASE585 All files read: True\n",
      "==============================================================\n",
      "CASE587 All files read: True\n",
      "==============================================================\n",
      "CASE588 All files read: True\n",
      "==============================================================\n",
      "CASE589 All files read: True\n",
      "==============================================================\n",
      "CASE593 All files read: True\n",
      "==============================================================\n",
      "CASE594 All files read: True\n",
      "==============================================================\n",
      "CASE596 All files read: True\n",
      "==============================================================\n",
      "CASE598 All files read: True\n",
      "==============================================================\n",
      "CASE600 All files read: True\n",
      "==============================================================\n",
      "CASE601 All files read: True\n",
      "==============================================================\n",
      "CASE602 All files read: True\n",
      "==============================================================\n",
      "CASE603 All files read: True\n",
      "==============================================================\n",
      "CASE604 All files read: True\n",
      "==============================================================\n",
      "CASE608 All files read: True\n",
      "==============================================================\n",
      "CASE610 All files read: True\n",
      "==============================================================\n",
      "CASE611 All files read: True\n",
      "==============================================================\n",
      "CASE615 All files read: True\n",
      "==============================================================\n",
      "CASE616 All files read: True\n",
      "==============================================================\n",
      "CASE621 All files read: True\n",
      "==============================================================\n",
      "CASE622 All files read: True\n",
      "==============================================================\n",
      "CASE623 All files read: True\n",
      "==============================================================\n",
      "CASE624 All files read: True\n",
      "==============================================================\n",
      "CASE630 All files read: True\n",
      "==============================================================\n",
      "CASE632 All files read: True\n",
      "==============================================================\n",
      "CASE635 All files read: True\n"
     ]
    }
   ],
   "source": [
    "# baseFilepath = 'PDAC-Response/PDAC-Response/ImagingData/Pre-treatment/CASE481_empty'\n",
    "# segmentFilePath = baseFilepath + '/CASE481_BASE_PRT_TUM_CV.seg.nrrd'\n",
    "# wholeFilePath = baseFilepath + '/CASE481_BASE_PRT_WHOLE_CT.nrrd' \n",
    "# whole, wholeHeader = nrrd.read(wholeFilePath)\n",
    "# segment, segmentHeader = nrrd.read(segmentFilePath)\n",
    "\n",
    "\n",
    "desiredSliceNumber=13\n",
    "allFolders = ['CASE244','CASE246','CASE247','CASE251','CASE254','CASE256','CASE263','CASE264','CASE265','CASE270','CASE272','CASE274',\n",
    "                'CASE467','CASE468','CASE470','CASE471','CASE472','CASE476','CASE479','CASE480','CASE482','CASE484','CASE485','CASE488','CASE494','CASE496','CASE499',\n",
    "                'CASE500','CASE505','CASE515','CASE520','CASE523','CASE525','CASE531','CASE533','CASE534','CASE535','CASE537','CASE539','CASE541','CASE543','CASE546','CASE547','CASE548','CASE549','CASE550','CASE551','CASE554','CASE555','CASE557','CASE559','CASE560','CASE562','CASE563','CASE564','CASE565','CASE568','CASE569','CASE572','CASE574','CASE575','CASE577','CASE578','CASE580','CASE581','CASE585','CASE586','CASE587','CASE588','CASE589','CASE593','CASE594','CASE596','CASE598',\n",
    "                'CASE600','CASE601','CASE602','CASE603','CASE604','CASE605','CASE608','CASE610','CASE611','CASE615','CASE616','CASE621','CASE622','CASE623','CASE624','CASE629','CASE630','CASE632','CASE635']\n",
    "\n",
    "\n",
    "# alreadySeen = ['CASE244','CASE246','CASE247','CASE251','CASE254','CASE256','CASE263','CASE264','CASE265','CASE270','CASE272','CASE274',\n",
    "#                 'CASE467','CASE468','CASE470','CASE471','CASE472','CASE476','CASE479','CASE480','CASE482','CASE484','CASE485','CASE488','CASE494','CASE496','CASE499',\n",
    "#                 'CASE500','CASE505','CASE515','CASE520','CASE523','CASE525','CASE531','CASE533','CASE534','CASE535','CASE537','CASE539','CASE541','CASE543','CASE546','CASE547','CASE548','CASE549','CASE550','CASE551','CASE554','CASE555','CASE557','CASE559','CASE560','CASE562','CASE563','CASE564','CASE565','CASE568','CASE569','CASE572','CASE574','CASE575','CASE577','CASE578','CASE580','CASE581','CASE585','CASE586','CASE587','CASE588','CASE589','CASE593','CASE594','CASE596','CASE598',\n",
    "#                 'CASE600','CASE601','CASE602','CASE603','CASE604','CASE605','CASE608','CASE610','CASE611','CASE615','CASE616','CASE621','CASE622','CASE623','CASE624','CASE629'\n",
    "# ]\n",
    "\n",
    "alreadySeen=[]\n",
    "baseFilepath = 'PDAC-Response/PDAC-Response/ImagingData/Pre-treatment-only-pres/'\n",
    "\n",
    "\n",
    "croppedSegmentsList = []\n",
    "\n",
    "for folder in os.listdir(baseFilepath):\n",
    "    # Skip cases that are not in the excel sheet\n",
    "    if folder not in cases:\n",
    "        continue\n",
    "    # Exclude to cases that we haven't seen yet\n",
    "    if folder in alreadySeen:\n",
    "        continue \n",
    "    count = 0\n",
    "    for file in os.listdir(os.path.join(baseFilepath,folder)):\n",
    "        \n",
    "        # if 'segmentation' in file or 'segmention' in file: # post-treatment segmentation \n",
    "        #     count+=1\n",
    "        #     postSegmentHeader = sitk.ReadImage(os.path.join(baseFilepath,folder,file))\n",
    "            \n",
    "        if 'TUM' in file or 'SMV' in file: # pre-treatment segmentation \n",
    "            count+=1\n",
    "            # segment, segmentHeader = nrrd.read(os.path.join(baseFilepath,folder,file))\n",
    "            preSegmentHeader = sitk.ReadImage(os.path.join(baseFilepath,folder,file))\n",
    "        elif file.endswith('CT.nrrd'): # whole ct scan\n",
    "            count+=1\n",
    "            wholeHeader = sitk.ReadImage(os.path.join(baseFilepath,folder,file))\n",
    "    \n",
    "    print('==============================================================')\n",
    "    print(folder, 'All files read:',count==2)\n",
    "      \n",
    "    whole, croppedSegment,error = preprocess(wholeHeader, preSegmentHeader, verbose=0) \n",
    "    if error:\n",
    "        print('Error in preprocessing')\n",
    "        # continue\n",
    "\n",
    "    #Update the number of slices so that it reaches desiredSliceNumber\n",
    "    updatedCroppedSegment = updateSlices(croppedSegment,desiredSliceNumber)\n",
    "\n",
    "    croppedSegmentsList.append(updatedCroppedSegment)\n",
    "    \n",
    "    # displayCroppedSegmentations(updatedCroppedSegment)\n",
    "\n",
    "# # For a single case\n",
    "# preSegmentHeader = sitk.ReadImage(os.path.join(baseFilepath,'CASE264/CASE264_BASE_PRT_TUM_CV.seg.nrrd'))\n",
    "# wholeHeader = sitk.ReadImage(os.path.join(baseFilepath,'CASE264/CASE264_BASE_PRT_WHOLE_CT.nrrd'))\n",
    "\n",
    "# whole, croppedSegment,error = preprocess(wholeHeader, preSegmentHeader, verbose=2) \n",
    "# if error:\n",
    "#     print('Error in preprocessing')\n",
    "#     # continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 64, 64, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(croppedSegmentsList))\n",
    "\n",
    "# croppedSegmentsList = np.array(croppedSegmentsList)\n",
    "# croppedSegmentsList.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLITING THE DATA INTO TRAIN AND TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain: 72\n",
      "yTrain: 72\n",
      "xTest: 13\n",
      "yTest: 13\n",
      "train recist category split: {1: 16, 2: 30, 3: 24}\n",
      "test recist category split: {1: 4, 2: 7, 3: 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(croppedSegmentsList, recistCriteria,test_size=0.15, random_state=42)\n",
    "\n",
    "print(f'xTrain: {len(xTrain)}')\n",
    "print(f'yTrain: {len(yTrain)}')\n",
    "print(f'xTest: {len(xTest)}')\n",
    "print(f'yTest: {len(yTest)}')\n",
    "\n",
    "# VIEWING THE CATEGORIZATION SPLITS OF THE TRAIN AND TEST SET\n",
    "\n",
    "# Add in 2 more progessive disease (1) into the test set\n",
    "for i in range(2):\n",
    "    idx = yTrain.index(1)\n",
    "    xTest.append(xTrain[idx])\n",
    "    yTest.append(yTrain[idx])\n",
    "    xTrain.pop(idx)\n",
    "    yTrain.pop(idx)\n",
    "\n",
    "#count the categorization splits of the train and test set\n",
    "trainRecistSplit = {y: yTrain.count(y) for y in yTrain}\n",
    "testRecistSplit = {y: yTest.count(y) for y in yTest}\n",
    "\n",
    "# Format the splits nicely into an ordered dictionary\n",
    "myKeys = list(trainRecistSplit.keys())\n",
    "myKeys.sort()\n",
    "trainRecistSplitDisplay = {i: trainRecistSplit[i] for i in myKeys}\n",
    "myKeys = list(testRecistSplit.keys())\n",
    "myKeys.sort()\n",
    "testRecistSplitDisplay = {i: testRecistSplit[i] for i in myKeys}\n",
    "\n",
    "print(f'train recist category split: {trainRecistSplitDisplay}')\n",
    "print(f'test recist category split: {testRecistSplitDisplay}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL DEFINITION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
